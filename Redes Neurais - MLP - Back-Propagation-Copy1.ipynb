{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Implementação MLP\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Funções de ativação"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import math\n",
    "from copy import deepcopy\n",
    "\n",
    "def sigmoid(x, derivate=False):\n",
    "    if(derivate):\n",
    "        # s = sigmoid(x)\n",
    "        return x * (1 - x)#s * (1 - s)}\n",
    "    return 1/(1+np.exp(-x))\n",
    "\n",
    "def gaussian(x, derivate=False):\n",
    "    if(derivate):\n",
    "        return -2 * np.exp(-np.power(x,2))\n",
    "    return np.exp(-np.power(x,2))\n",
    "\n",
    "def identity(x, derivate=False):\n",
    "    if(derivate):\n",
    "        return 1\n",
    "    return x\n",
    "\n",
    "def sinusoid(x, derivate=False):\n",
    "    if(derivate):\n",
    "        return np.cos(x)\n",
    "    return np.sin(x)\n",
    "\n",
    "def relu(x, derivate=False):\n",
    "    if(derivate):\n",
    "        x[x >= 0] = 1\n",
    "        x[not x0s] = 0\n",
    "    x[x<0] = 0.0\n",
    "    return x\n",
    "\n",
    "def softmax(x, derivate=False):\n",
    "    return np.exp(x) / sum(np.exp(x))\n",
    "\n",
    "\n",
    "def mean_square_error(expected_data, predicted_data):\n",
    "    return ((expected_data - predicted_data) ** 2).mean(axis=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# K fold\n",
    "\n",
    "def kFold(data_len, foldsNum):\n",
    "    indices = [ x[0] for x in np.ndindex(data_len)]\n",
    "    np.random.shuffle(indices)\n",
    "    \n",
    "    numPerFold = int(data_len / foldsNum)\n",
    "    folds = []\n",
    "    fold = []\n",
    "    count = 0\n",
    "    for i in indices:\n",
    "        count+=1\n",
    "        fold.append(i)\n",
    "        if(count == numPerFold):\n",
    "            folds.append(fold)\n",
    "            fold = []\n",
    "            count = 0\n",
    "    seq = []\n",
    "    \n",
    "    for i in range(foldsNum):\n",
    "        d = [x for x in range(foldsNum)]\n",
    "        d.remove(i)\n",
    "        seq.append((d, i))\n",
    "    return seq, folds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implementação da Rede + Backpropagation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pdb\n",
    "\n",
    "class MLPNeuralNetwork():\n",
    "    def __init__(self, inputNum, hidden):\n",
    "        self.weights, self.bias, self.activations = self.__create_network__(inputNum, hidden)\n",
    "        \n",
    "        \n",
    "    def __create_network__(self, inputNum, architecture):\n",
    "        activations = []\n",
    "        bias = []\n",
    "        weights = []\n",
    "        \n",
    "        layer = architecture[0]\n",
    "        activations.append(layer[1])\n",
    "        weights.append(np.random.rand(inputNum, layer[0]))\n",
    "        bias.append(np.random.rand(layer[0]))\n",
    "        \n",
    "        for i in range(1, len(architecture)):\n",
    "            layer = architecture[i]\n",
    "            activations.append(layer[1])\n",
    "            weights.append(np.random.rand(architecture[i-1][0], layer[0]))\n",
    "            bias.append(np.random.rand(layer[0]))\n",
    "            \n",
    "        return weights, bias, activations\n",
    "\n",
    "\n",
    "    def predict(self, input_, retInt=False):\n",
    "        if(retInt):\n",
    "            outputs = []\n",
    "\n",
    "        output = None\n",
    "        for i in range(len(self.weights)):\n",
    "            output = self.activations[i](input_.dot(self.weights[i]) + self.bias[i])\n",
    "            input_ = output\n",
    "            \n",
    "            if(retInt):\n",
    "                outputs.append(output)\n",
    "        if(retInt):\n",
    "            return output, outputs\n",
    "        else:\n",
    "            return output\n",
    "        \n",
    "    def score(self, inputs, outputs):\n",
    "        predictions = []\n",
    "        #pdb.set_trace()\n",
    "        for input_ in inputs:\n",
    "            p = self.predict(input_, retInt=False).tolist()\n",
    "            if(len(p)==1):\n",
    "                predictions+= p\n",
    "            else:\n",
    "                predictions.append(p)\n",
    "        # \n",
    "        return mean_square_error(outputs, np.array(predictions))\n",
    "    \n",
    "    \n",
    "    # calcula os deltas \n",
    "    def back_propagate(self, input_, expected, verbose=False):\n",
    "        # print(\"back_propagate\")\n",
    "        output, outputs = self.predict(input_, retInt=True)\n",
    "        if(verbose):\n",
    "            print(\"outputs: \", outputs)\n",
    "        deltas = []\n",
    "        for index in reversed(range(len(self.weights))):\n",
    "            error = None\n",
    "            if index == len(self.weights) - 1:#camada de saída\n",
    "                delta = (output - expected) * self.activations[index](output, derivate=True) # correto\n",
    "                if(verbose):\n",
    "                    print(\"delta of output layer\", delta)\n",
    "            else:\n",
    "                delta = self.weights[index+1].dot(deltas[0].T) * self.activations[index](outputs[index], derivate=True)\n",
    "                if(verbose):\n",
    "                    print(\"output layer before is, \", outputs[index])\n",
    "                    print(\"weigts * \", self.weights[index+1])\n",
    "                    print(\"input t'\", outputs[index])\n",
    "                    print(\"delta * \", delta[0].T)\n",
    "                    print(\"delta result\", delta)\n",
    "            deltas.insert(0,delta)\n",
    "        return deltas, output, outputs\n",
    "\n",
    "    def calculate_delta_w(self, deltas, outputs, learnRate, input_):\n",
    "        w_deltas = []\n",
    "        bias_deltas = []\n",
    "        for index in range(len(self.weights)):\n",
    "            if(index == 0):\n",
    "                w_deltas.append((-learnRate * input_.T * (deltas[index].reshape(len(deltas[index]), 1))).T)\n",
    "            else:\n",
    "                w_deltas.append(np.array(-learnRate * (outputs[index-1].reshape(\n",
    "                    len(outputs[index-1]), 1))* deltas[index]))\n",
    "            bias_deltas.append(-learnRate * 1 * deltas[index])\n",
    "        return w_deltas, bias_deltas\n",
    "    \n",
    "    \n",
    "    def __update_weights_batelada__(self, wDeltas, bDeltas, learnRate, N):\n",
    "        # pdb.set_trace()\n",
    "        for index in range(len(self.weights)):\n",
    "            self.weights[index] +=  wDeltas[index]\n",
    "            self.bias[index] +=     bDeltas[index]\n",
    "    \n",
    "    def update_weights_padrao(self, deltas, outputs, learnRate, input_, verbose=False):\n",
    "        for index in range(len(self.weights)):\n",
    "            if(index == 0):\n",
    "                self.weights[index] += (-learnRate * input_.T * (deltas[index].reshape(len(deltas[index]), 1))).T\n",
    "            else:\n",
    "                #pdb.set_trace()\n",
    "                self.weights[index] += np.array(-learnRate * (outputs[index-1].reshape(\n",
    "                    len(outputs[index-1]), 1))* deltas[index])\n",
    "            self.bias[index] +=   -learnRate * 1 * deltas[index]\n",
    "            \n",
    "    def __train_network__(self, input_, expected_, learnRate, maxError, num_it):\n",
    "        for iteration in range(num_it):\n",
    "            deltas, output, outputs = self.back_propagate( input_, expected_)\n",
    "            self.update_weights(deltas, outputs, learnRate)\n",
    "            \n",
    "            totalError = mean_square_error(expected_, output)\n",
    "            print(\"iteration {} error {}\".format(iteration, totalError))\n",
    "            if(totalError < maxError):\n",
    "                print(\"Treinamento finalizado\")\n",
    "                break\n",
    "    \n",
    "    def train_network_padrao(self, input_, expected_, learnRate, maxError, num_it, randomize=True):\n",
    "        for iteration in range(num_it):\n",
    "            totalError = []\n",
    "            indices = [ x[0] for x in np.ndindex(len(inputs))]\n",
    "\n",
    "            if randomize:\n",
    "                np.random.shuffle(indices)\n",
    "\n",
    "            for index in indices:#np.random.randint(len(input_), size=len(input_)):\n",
    "                deltas, output, outputs = self.back_propagate( input_[index], expected_[index])\n",
    "                self.update_weights_padrao(deltas, outputs, learnRate, input_[index])\n",
    "                #totalError.append(mean_square_error(expected_[index], output))\n",
    "            #totalError = sum(totalError) / len(totalError)\n",
    "            totalError = self.score(input_, expected_)\n",
    "            if(iteration % 1000 == 0):\n",
    "                print(\"iteration {} error {}\".format(iteration, totalError))\n",
    "            if(totalError < maxError):\n",
    "                print(\"Treinamento finalizado\")\n",
    "                break\n",
    "        print(\"num iterações: \", iteration)\n",
    "                \n",
    "    def train_network_batelada(self, input_, expected_, learnRate=0.1, alpha=2, maxError=0.01, num_it=10000,\n",
    "                              randomize=True):\n",
    "        for iteration in range(num_it):\n",
    "            wDeltaTotal = None\n",
    "            bDeltaTotal = None\n",
    "            totalError = []\n",
    "            indices = [ x[0] for x in np.ndindex(len(inputs))]\n",
    "\n",
    "            if randomize:\n",
    "                np.random.shuffle(indices)\n",
    "\n",
    "            for index in indices:#np.random.randint(len(input_), size=len(input_)):\n",
    "                deltas, output, outputs = self.back_propagate( input_[index], expected_[index])\n",
    "                w_deltas, bDeltas = self.calculate_delta_w(deltas, outputs, learnRate, input_[index])\n",
    "                # pdb.set_trace()\n",
    "                \n",
    "                if(wDeltaTotal is None):\n",
    "                    wDeltaTotal=w_deltas\n",
    "                    bDeltaTotal=bDeltas\n",
    "                else:\n",
    "                    for i in range(len(wDeltaTotal)):\n",
    "                        wDeltaTotal[i]+=np.array(w_deltas[i])\n",
    "                        bDeltaTotal[i]+=np.array(bDeltas[i])\n",
    "                # print(\"nxx delta:\", wDeltaTotal, \"bias\", bDeltaTotal)\n",
    "\n",
    "            self.__update_weights_batelada__(wDeltaTotal, bDeltaTotal, learnRate, len(input_))\n",
    "\n",
    "            totalError = self.score(input_, expected_)\n",
    "            \n",
    "            if(iteration % 1000 == 0):\n",
    "                print(\"iteration {} error {}\".format(iteration, totalError))\n",
    "            if(totalError < maxError):\n",
    "                print(\"Treinamento finalizado\")\n",
    "                break\n",
    "        print(\"num iterações: \", iteration)\n",
    "        \n",
    "    def copy(self):\n",
    "        return deepcopy(self)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tarefa 01. XOR\n",
    "\n",
    "Classificação XOR: (rede 2 => 2 => 1) para avaliar a implementacao do\n",
    "algoritmo Backpropagation para MLP\n",
    "Testar com o treinamento por padrão e por batelada"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Leitura dos dados de treinamento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from numpy import genfromtxt\n",
    "\n",
    "# read input data\n",
    "xor_data = genfromtxt('datasets/xor.csv', delimiter=',', skip_header=1)\n",
    "\n",
    "inputs = xor_data[:,0:2]\n",
    "outputs = xor_data[:,2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "treinamento por padrão\n",
      "iteration 0 error 0.2626618087012363\n",
      "iteration 1000 error 0.19069433659569066\n",
      "iteration 2000 error 0.01168895090784159\n",
      "Treinamento finalizado\n",
      "num iterações:  2088\n",
      "score padrão:  0.009996056619279374\n"
     ]
    }
   ],
   "source": [
    "xor_network = MLPNeuralNetwork(inputNum=2, hidden=[\n",
    "    (2, sigmoid), (1, sigmoid)])\n",
    "\n",
    "print(\"treinamento por padrão\")\n",
    "xor_network.train_network_padrao(inputs, outputs, learnRate=0.3, maxError=0.01, num_it=10000)\n",
    "\n",
    "print(\"score padrão: \", xor_network.score(inputs, outputs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 0.] [0.09773129]\n",
      "[0. 1.] [0.90332645]\n",
      "[1. 0.] [0.90311013]\n",
      "[1. 1.] [0.10816376]\n"
     ]
    }
   ],
   "source": [
    "for input_ in inputs:\n",
    "    print(input_, xor_network.predict(input_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "treinamento por batelada\n",
      "iteration 0 error 0.2842019664380314\n",
      "Treinamento finalizado\n",
      "num iterações:  318\n",
      "score padrão:  0.009918156249898651\n"
     ]
    }
   ],
   "source": [
    "xor_network = MLPNeuralNetwork(inputNum=2, hidden=[\n",
    "    (2, sigmoid), (1, sigmoid)])\n",
    "\n",
    "print(\"treinamento por batelada\")\n",
    "xor_network.train_network_batelada(inputs, outputs, learnRate=2, maxError=0.01, num_it=10000)\n",
    "\n",
    "print(\"score padrão: \", xor_network.score(inputs, outputs))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Iris Dataset Classification\n",
    "\n",
    "InfoDadosIris.pdf (rede 4 => ? => 1) Versus rede 4 => ? => 3)\n",
    "\n",
    "- Testar RNs com diferentes números de neurônios na camada de saída:\n",
    "     - 1 único neurônio\n",
    "     - 3 neurônios de saída (1 para cada classe)\n",
    "- Testar diferentes números de neurônios na camada escondida\n",
    "- Testar diferentes funções de ativação (sigmoide, tg hip, ....)\n",
    "- Testar diferentes taxas de apresendizado\n",
    "- Testar Bakpropagation com e sem momento\n",
    "\n",
    "Para cada caso acima, implementar o 5-fold cross validation e apresentar para\n",
    "cada caso a média dos resultados de acurácia da rede. As comparações entre os\n",
    "diferentes parâmetros devem ser feitas com relação à acurácia média em cada\n",
    "caso.\n",
    "\n",
    "Obs: verificar a questão da inicialização dos pesos (como isso afeta o\n",
    "algoritmo)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# read input data\n",
    "iris_data =  pd.read_csv('datasets/IrisDataset.csv', delimiter=',')\n",
    "\n",
    "convOne = {'Iris-setosa': 0,\n",
    "'Iris-versicolor': 1,\n",
    " 'Iris-virginica': 2\n",
    "}\n",
    "\n",
    "convThree = {'Iris-setosa': np.array([1, 0, 0]),\n",
    "'Iris-versicolor': np.array([0, 1, 0]),\n",
    " 'Iris-virginica': np.array([0, 0, 1])\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "inputs  = np.array(iris_data.iloc[:,0:4])\n",
    "outputs = np.array(iris_data.iloc[:,-1])\n",
    "\n",
    "\n",
    "outputsOne = np.array([convOne[x] for x in outputs] )\n",
    "\n",
    "outputsThree = np.array([convThree[x] for x in outputs]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def crossMLP(network_base, inputs, outputs, foldsNum=5):\n",
    "    seq, folds = kFold(len(inputs), foldsNum)\n",
    "    \n",
    "    score = []\n",
    "    for index in range(foldsNum):\n",
    "        network = network_base.copy()\n",
    "        _train, _test = seq[index]\n",
    "        train = []\n",
    "        for x in _train:\n",
    "            train += folds[x]\n",
    "        test =  folds[_test]\n",
    "        print(train)\n",
    "        network.train_network_padrao(inputs[train], outputs[train], learnRate=0.1, \n",
    "                                 maxError=0.05, num_it=10000)\n",
    "        score.append(network.score(inputs[test], outputs[test]))\n",
    "    \n",
    "    return sum(score)/foldsNum\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1 neurônio na camada de saída"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration 0 error 0.6665392595404562\n",
      "iteration 1000 error 0.33349850045325086\n",
      "iteration 2000 error 0.3334133711388228\n",
      "iteration 3000 error 0.33338611063666046\n",
      "iteration 4000 error 0.3333726908630321\n",
      "iteration 5000 error 0.3333647076394897\n",
      "iteration 6000 error 0.33335941468013774\n",
      "iteration 7000 error 0.3333556485795166\n",
      "iteration 8000 error 0.3333528321329673\n"
     ]
    }
   ],
   "source": [
    "iris_network = MLPNeuralNetwork(inputNum=4, hidden=[\n",
    "(10, sigmoid), (1, sigmoid)])\n",
    "\n",
    "iris_network.train_network_padrao(inputs, outputsOne, learnRate=0.1, \n",
    "                                 maxError=0.05, num_it=10000)\n",
    "\n",
    "iris_network.score(inputs, outputOne)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "score = crossMLP(iris_network, inputs, outputsOne)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3 neurônios na camada de saída"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration 0 error 0.666623108571756\n",
      "Treinamento finalizado\n",
      "num iterações:  547\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.03779873983210967"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iris_network = MLPNeuralNetwork(inputNum=4, hidden=[\n",
    "(20, sigmoid), (3, sigmoid)])\n",
    "\n",
    "iris_network.train_network_padrao(inputs, outputsThree, learnRate=0.1, \n",
    "                                 maxError=0.05, num_it=10000)\n",
    "\n",
    "iris_network.score(inputs, outputsThree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration 0 error 0.6666428939294694\n",
      "iteration 1000 error 0.3333331502998912\n",
      "iteration 2000 error 0.33333313426503675\n",
      "iteration 3000 error 0.33333311514583674\n",
      "iteration 4000 error 0.33333309195820715\n",
      "iteration 5000 error 0.33333306324975903\n",
      "iteration 6000 error 0.33333302678368726\n",
      "iteration 7000 error 0.3333329789267003\n",
      "iteration 8000 error 0.33333291335801063\n",
      "iteration 9000 error 0.3333328180216999\n",
      "num iterações:  9999\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.33333266691263763"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iris_network = MLPNeuralNetwork(inputNum=4, hidden=[\n",
    "(20, sigmoid), (3, sigmoid)])\n",
    "\n",
    "iris_network.train_network_batelada(inputs, outputsThree, learnRate=0.1, \n",
    "                                 maxError=0.05, num_it=10000)\n",
    "\n",
    "iris_network.score(inputs, outputsThree)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Facebook Metrics Regression\n",
    "\n",
    " Regressão: Dados Facebook Metrics (rede 18 => ? => 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "facebook_data = pd.read_csv('datasets/dataset_Facebook.csv', delimiter=';')\n",
    "\n",
    "#print(facebook_data.head())\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
